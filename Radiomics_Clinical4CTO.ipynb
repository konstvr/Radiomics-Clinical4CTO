{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Radiomics&Clinical data 4 CTO"
      ],
      "metadata": {
        "id": "o03aOVAw0Etg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Baselines\n",
        "!pip install catboost xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QWvColw1Llh",
        "outputId": "612c0ea4-065a-4766-f25b-9231037e54d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üïÆ Necessary Imports for the Notebook\n",
        "\n",
        "The examples in this notebook require the following imports.\n",
        "Make sure to run this cell before any other cell.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iro4vB3w4rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, r2_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "# Baseline Imports\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor"
      ],
      "metadata": {
        "id": "fanTdoI22D8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload Dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "6lCuYJ0nONYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('Your_data.xlsx')"
      ],
      "metadata": {
        "id": "ODWJvSrnxaUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "dhWAjTsScYun"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# 1. Basic Data Exploration\n",
        "print(\"Shape of the dataset:\", df.shape)\n",
        "\n",
        "# 2. Descriptive Statistics\n",
        "print(\"\\nDescriptive statistics:\\n\", df.describe())  # Summary statistics for numerical columns\n",
        "df = df.dropna(subset=['FAIL'])\n",
        "print(\"\\nClass distribution (FAIL column):\\n\", df['FAIL'].value_counts())  # Distribution of classes\n",
        "\n",
        "# 3. Visualizations\n",
        "ax = df['FAIL'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "ax.set_xticklabels(['Success', 'Fail'])\n",
        "plt.title('Operation outcome')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)  # Keep x-axis labels horizontal\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-LABp2CIaUMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check data format\n",
        "unconvertible_columns = []\n",
        "\n",
        "def convert_to_float(x, column_name):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except ValueError:\n",
        "        if column_name not in unconvertible_columns:\n",
        "            unconvertible_columns.append(column_name)\n",
        "        return x\n",
        "\n",
        "# Apply the function to all columns\n",
        "for column in df.columns:\n",
        "    df[column] = df[column].apply(lambda x: convert_to_float(x, column))\n",
        "\n",
        "print(\"Columns with unconvertible values:\", unconvertible_columns)"
      ],
      "metadata": {
        "id": "HF4KX5AkM9wq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing data (NaN)\n",
        "rows_with_missing_data = df[df.isnull().any(axis=1)]\n",
        "num_rows_with_missing_data = len(rows_with_missing_data)\n",
        "\n",
        "#rows with strings\n",
        "rows_with_strings = df[df.applymap(lambda x: isinstance(x, str)).any(axis=1)]\n",
        "num_rows_with_strings = len(rows_with_strings)\n",
        "\n",
        "print(f\"Number of rows with missing data: {num_rows_with_missing_data}\")\n",
        "print(f\"Number of rows with strings: {num_rows_with_strings}\")"
      ],
      "metadata": {
        "id": "nFwMaBlLJS0j",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = df.drop(columns=unconvertible_columns)"
      ],
      "metadata": {
        "id": "8Ij1okqyN2UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta Feature Selection"
      ],
      "metadata": {
        "id": "xTymNOfpEAU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Boruta"
      ],
      "metadata": {
        "id": "ByhBF3REInDU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split before boruta"
      ],
      "metadata": {
        "id": "Ks72sLT1dcwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = cleaned_df.drop('FAIL', axis=1)\n",
        "y = cleaned_df['FAIL']"
      ],
      "metadata": {
        "id": "zXzcahZDdlJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "#Convert y_train and y_test to Pandas Series to use value_counts()\n",
        "y_train_series = pd.Series(y_train)\n",
        "y_test_series = pd.Series(y_test)\n",
        "\n",
        "print(y_train_series.value_counts(), y_test_series.value_counts())"
      ],
      "metadata": {
        "id": "3iIJcafUdbqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For radiomics-clinical\n",
        "#Split the X into radiomics and clinical\n",
        "strength_index = X_train.columns.get_loc('Strength_864')\n",
        "\n",
        "#df1: (up to 'strength_864' + 'FAIL')\n",
        "X_train1_columns = X_train.columns[:strength_index + 1].tolist()\n",
        "X_train1 = X_train[X_train1_columns]\n",
        "print(X_train1_columns)\n",
        "\n",
        "#df2\n",
        "X_train2_columns = [col for col in X_train.columns if col not in X_train1_columns]\n",
        "X_train2 = X_train[X_train2_columns]\n",
        "print(X_train2.columns)"
      ],
      "metadata": {
        "id": "PMlWQ42shxbh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separate Boruta\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#for X1\n",
        "rf1 = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "feat_selector1 = BorutaPy(rf1, n_estimators='auto', verbose=2, random_state=1)\n",
        "feat_selector1.fit(X_train1.values, y_train)\n",
        "X1_filtered = feat_selector1.transform(X_train1.values)\n",
        "selected_features1 = X_train1.columns[feat_selector1.support_]\n",
        "\n",
        "#for X2\n",
        "rf2 = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "feat_selector2 = BorutaPy(rf2, n_estimators='auto', verbose=2, random_state=1)\n",
        "feat_selector2.fit(X_train2.values, y_train)\n",
        "X2_filtered = feat_selector2.transform(X_train2.values)\n",
        "selected_features2 = X_train2.columns[feat_selector2.support_]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FvJ4tJeLleeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For combined clinincal and radiomics"
      ],
      "metadata": {
        "id": "cQghtjUjaDTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate selected features\n",
        "X_train_selected = pd.concat([X_train1[selected_features1], X_train2[selected_features2]], axis=1)\n",
        "all_selected_features = selected_features1.tolist() + selected_features2.tolist()\n",
        "\n",
        "#select for X_test\n",
        "X_test_selected = X_test[all_selected_features]"
      ],
      "metadata": {
        "id": "sn_1DxsCl_ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For radiomics vs clinical"
      ],
      "metadata": {
        "id": "CIa3uqrcaVqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_selected = X_train1[selected_features1]\n",
        "#X_train_selected = X_train2[selected_features2]\n",
        "\n",
        "X_test_selected = X_test[selected_features1]\n",
        "#X_test_selected = X_test[selected_features2]"
      ],
      "metadata": {
        "id": "6U3FRxltaHCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess dataset"
      ],
      "metadata": {
        "id": "c21DbhrIkV3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled = scaler.transform(X_test_selected)"
      ],
      "metadata": {
        "id": "7qnUP04EkY9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train models"
      ],
      "metadata": {
        "id": "5aOiCA2e202U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with baselines\n",
        "y_pred_xgb = XGBClassifier(random_state=42).fit(X_train_scaled, y_train).predict_proba(X_test_scaled)\n",
        "y_pred_cat = CatBoostClassifier(random_state=42, verbose=0).fit(X_train_scaled, y_train).predict_proba(X_test_scaled)\n",
        "y_pred_rf = RandomForestClassifier(random_state=42).fit(X_train_scaled, y_train).predict_proba(X_test_scaled)\n",
        "#y_pred_lr = LinearRegression().fit(X_train_scaled, y_train).predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "zTHzDedu3DKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from sklearn.metrics import roc_auc_score, matthews_corrcoef, f1_score\n",
        "\n",
        "#performance\n",
        "model_scores = []\n",
        "\n",
        "for model_name, y_pred_proba in [(\"XGBoost\", y_pred_xgb), (\"RandomForest\", y_pred_rf), (\"CatBoost\", y_pred_cat)]:\n",
        "    y_pred = (y_pred_proba[:, 1] > 0.4).astype(int)\n",
        "\n",
        "    auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    model_scores.append([model_name, auc, mcc, f1])\n",
        "\n",
        "#scores\n",
        "scores_df = pd.DataFrame(model_scores, columns=[\"Model\", \"AUC\", \"MCC\", \"F1-Score\"])\n",
        "\n",
        "#F1 plot\n",
        "ax = scores_df.plot.barh(x=\"Model\", y=\"F1-Score\")\n",
        "ax.set_xlim(0, 1)  # Set x-axis limits for F1-score (0 to 1)\n",
        "plt.title(\"F1-Scores of Models\")\n",
        "plt.show()\n",
        "\n",
        "#scores table\n",
        "print(scores_df)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VKywP6c1oREA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}